{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21a6f8dc",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "we are using the following dataset to predict mental disorder. it contain 17 psychology symptoms(used by psychiatrists to describe mental disorder.) which is a collection of 120 patients. using this dataset we can predict mental disorder for each patient. in this dataset we are using logistic regression, random forest and support vector classification. the following dataset can easily be improved by doing a survey or collecting more data and adding them to our data set. that way we can improve our model's accuracy. but for this project this dataset works fine. the reason why we are using these algorithms will be discussed in below slides."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f6e9f",
   "metadata": {},
   "source": [
    "### Problem statement\n",
    "with the technological advancement, different AI apps and machines are being used not only in productions and \n",
    "education but also in healthcare. theres a huge need to use and create and use technologies that that can analyze,\n",
    "predict, different diseases. therefor we using the following data set to predict mental disorder. our goal is to \n",
    "create a pypline with the best possible accuracy. therefor we re choosing three different algorithms which are:\n",
    "Logistic Regression, Random Forest and Support Vector Machine. and then we choose the model with the highest \n",
    "accuracy and then test our model on that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59cb5f3",
   "metadata": {},
   "source": [
    "link to the dateset: \n",
    "    https://www.kaggle.com/datasets/cid007/mental-disorder-classification/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaec65e",
   "metadata": {},
   "source": [
    "### Importing libraries\n",
    "\n",
    "below i have imported the required algorithms and libraries. each of them will be discussed step by step when we use them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11154118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e453db",
   "metadata": {},
   "source": [
    "### Loading The Dataset\n",
    "after loading the dataset we use head method to see our data. by default head method shows the first five rows.\n",
    "we use this opportunity to take a closer look at our dataset and understand our data. as you can see below,\n",
    "our target is Expert Diangose and all other columns are our features. we use features to predict our target. now the main part here is to identify, is it supervised learning problem or unsupervised. it is obvious that it is supervised because we are using labeled data or input to predict mental disorder. in supervised we have regression \n",
    "and classification. in this case, we are using classification here beause our target value is categorical. and  as we know regresson is used for linear problems or when our target is continuous such as, famous examples, house price or stock market. then we are using classification algorthms such as Logistic regression, Random forest and supprt vector. we can also use decision tree and knn but in our case three algorithms are enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f75104df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient Number</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Euphoric</th>\n",
       "      <th>Exhausted</th>\n",
       "      <th>Sleep dissorder</th>\n",
       "      <th>Mood Swing</th>\n",
       "      <th>Suicidal thoughts</th>\n",
       "      <th>Anorxia</th>\n",
       "      <th>Authority Respect</th>\n",
       "      <th>Try-Explanation</th>\n",
       "      <th>Aggressive Response</th>\n",
       "      <th>Ignore &amp; Move-On</th>\n",
       "      <th>Nervous Break-down</th>\n",
       "      <th>Admit Mistakes</th>\n",
       "      <th>Overthinking</th>\n",
       "      <th>Sexual Activity</th>\n",
       "      <th>Concentration</th>\n",
       "      <th>Optimisim</th>\n",
       "      <th>Expert Diagnose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patiant-01</td>\n",
       "      <td>Usually</td>\n",
       "      <td>Seldom</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>3 From 10</td>\n",
       "      <td>3 From 10</td>\n",
       "      <td>4 From 10</td>\n",
       "      <td>Bipolar Type-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patiant-02</td>\n",
       "      <td>Usually</td>\n",
       "      <td>Seldom</td>\n",
       "      <td>Usually</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>4 From 10</td>\n",
       "      <td>2 From 10</td>\n",
       "      <td>5 From 10</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patiant-03</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Most-Often</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>6 From 10</td>\n",
       "      <td>5 From 10</td>\n",
       "      <td>7 From 10</td>\n",
       "      <td>Bipolar Type-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patiant-04</td>\n",
       "      <td>Usually</td>\n",
       "      <td>Seldom</td>\n",
       "      <td>Usually</td>\n",
       "      <td>Most-Often</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>3 From 10</td>\n",
       "      <td>2 From 10</td>\n",
       "      <td>2 From 10</td>\n",
       "      <td>Bipolar Type-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patiant-05</td>\n",
       "      <td>Usually</td>\n",
       "      <td>Usually</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>5 From 10</td>\n",
       "      <td>5 From 10</td>\n",
       "      <td>6 From 10</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Patient Number    Sadness    Euphoric  Exhausted Sleep dissorder Mood Swing  \\\n",
       "0     Patiant-01    Usually      Seldom  Sometimes       Sometimes        YES   \n",
       "1     Patiant-02    Usually      Seldom    Usually       Sometimes         NO   \n",
       "2     Patiant-03  Sometimes  Most-Often  Sometimes       Sometimes        YES   \n",
       "3     Patiant-04    Usually      Seldom    Usually      Most-Often        YES   \n",
       "4     Patiant-05    Usually     Usually  Sometimes       Sometimes         NO   \n",
       "\n",
       "  Suicidal thoughts Anorxia Authority Respect Try-Explanation  \\\n",
       "0              YES       NO                NO             YES   \n",
       "1               YES      NO                NO              NO   \n",
       "2                NO      NO                NO             YES   \n",
       "3               YES     YES                NO             YES   \n",
       "4                NO      NO                NO              NO   \n",
       "\n",
       "  Aggressive Response Ignore & Move-On Nervous Break-down Admit Mistakes  \\\n",
       "0                  NO               NO                YES            YES   \n",
       "1                  NO               NO                 NO             NO   \n",
       "2                 YES               NO                YES            YES   \n",
       "3                  NO               NO                 NO             NO   \n",
       "4                  NO               NO                YES            YES   \n",
       "\n",
       "  Overthinking Sexual Activity Concentration  Optimisim Expert Diagnose  \n",
       "0          YES       3 From 10     3 From 10  4 From 10  Bipolar Type-2  \n",
       "1           NO       4 From 10     2 From 10  5 From 10      Depression  \n",
       "2           NO       6 From 10     5 From 10  7 From 10  Bipolar Type-1  \n",
       "3           NO       3 From 10     2 From 10  2 From 10  Bipolar Type-2  \n",
       "4          YES       5 From 10     5 From 10  6 From 10          Normal  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Mental-Disorders.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eae7d4",
   "metadata": {},
   "source": [
    "### INFO\n",
    "we are using info method to see the count of null values, data types, column names and number of columns and rows\n",
    "as well. we can also use describe method to check the statistical info of our data, or other methods such columns \n",
    "to print our the name of the columns, or print number of null values and etc. but im using only info here cuz it \n",
    "gives all the required informaton that i need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "931ace23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Patient Number       120 non-null    object\n",
      " 1   Sadness              120 non-null    object\n",
      " 2   Euphoric             120 non-null    object\n",
      " 3   Exhausted            120 non-null    object\n",
      " 4   Sleep dissorder      120 non-null    object\n",
      " 5   Mood Swing           120 non-null    object\n",
      " 6   Suicidal thoughts    120 non-null    object\n",
      " 7   Anorxia              120 non-null    object\n",
      " 8   Authority Respect    120 non-null    object\n",
      " 9   Try-Explanation      120 non-null    object\n",
      " 10  Aggressive Response  120 non-null    object\n",
      " 11  Ignore & Move-On     120 non-null    object\n",
      " 12  Nervous Break-down   120 non-null    object\n",
      " 13  Admit Mistakes       120 non-null    object\n",
      " 14  Overthinking         120 non-null    object\n",
      " 15  Sexual Activity      120 non-null    object\n",
      " 16  Concentration        120 non-null    object\n",
      " 17  Optimisim            120 non-null    object\n",
      " 18  Expert Diagnose      120 non-null    object\n",
      "dtypes: object(19)\n",
      "memory usage: 17.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da71e96b",
   "metadata": {},
   "source": [
    "### Splitting Data\n",
    "in this part, I am splitting the data into two variables x and y. Then I am dropping the patient number and expert diagnose, because expert diagnose is our terget and patient number we dont need it. then we assign the test size into 0.2 which means 20% of the data should be use for testing purposes. and random state means that parameters remain constant. once we split the data and define variables for the train and test such as x_train, y_train, x_test and y_test, we move on to print their values to make sure theyre splited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b0173733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (96, 17)\n",
      "Shape of y_train: (96,)\n",
      "Shape of x_test: (24, 17)\n",
      "Shape of y_test: (24,)\n"
     ]
    }
   ],
   "source": [
    "x = df.drop(['Patient Number','Expert Diagnose'],axis=1)\n",
    "y = df['Expert Diagnose']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of x_test:\", x_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6e50a8",
   "metadata": {},
   "source": [
    "### Tranforming Data Using Column Transformer\n",
    "  we are using column tranformer to convert our data into numerical data types using one hot encoder. since our algorithms that we are using below require numerical data, we need to convert them using one hot encoder. we can also use pandas method get_dummies to convert them as well. but to keep the code clean and readable we re using one hot encoder inside the column transformer and then we use the object data type which we stored in a variable called categorical and convert it to numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "03cd92e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = x_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "class_trans = ColumnTransformer([\n",
    "    ('OneHotEncoder',OneHotEncoder(),categorical),\n",
    "],remainder = 'passthrough')\n",
    "class_trans.fit(x_train)\n",
    "x_train = class_trans.transform(x_train)\n",
    "x_test = class_trans.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa705d5",
   "metadata": {},
   "source": [
    "### Logistic Regression Model  \n",
    "    below we are initialzing logistic regression model using grid search cross validation. params grid is dic \n",
    "    where we set our search points or hyperparameters which in this case, C represents different levels of regul\n",
    "    -arization, and max iteration represents iteration limit. grid search uses different hyperparameters that we \n",
    "    assigned below like cv =5 which means 5 fold, scoring accuracy and and njobs to find the best comb of \n",
    "    hyperparameters. after runnung the model we can see that the accuracy is 83 percent  which is a good\n",
    "    starting point and numner of max iteration 50 and c is 0.1 are the best params for this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "31ada88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'max_iter': 50}\n",
      "0.8321052631578947\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1],\n",
    "    'max_iter': [50, 100, 150],\n",
    "}\n",
    "\n",
    "LR = GridSearchCV(LogisticRegression(), param_grid=param_grid ,cv=5, scoring='accuracy',n_jobs=-1)\n",
    "LR.fit(x_train, y_train)\n",
    "\n",
    "print(LR.best_params_)\n",
    "print(LR.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf8010a",
   "metadata": {},
   "source": [
    "### Random Forest Model\n",
    "  same as above this time we are using random forest and set it parameters to max dept(of each tree), \n",
    "  n_estimators (number of trees) and so on. and then we use gridsearch CV and assign it to a parameter called RF. we can set the parameters in param_grid and see which one works fits better. after running the model we can see its accuracy is 87 percent which is a lot better than logistic regression. and its best parameters as shown below are max_depth  equal to 5, log2 which means the root square of the total number of features wll be considered in each split and n estimator represents number of decision trees in forest which is 150 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cf09b3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "0.8742105263157894\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "RF = GridSearchCV(RandomForestClassifier(), param_grid=param_grid ,cv=5, scoring='accuracy',n_jobs=-1)\n",
    "RF.fit(x_train, y_train)\n",
    "\n",
    "print(RF.best_params_)\n",
    "print(RF.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d0fd96",
   "metadata": {},
   "source": [
    "### Support Vector Classification - SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8825ce22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001, 'gamma': 1, 'kernel': 'poly'}\n",
      "0.8221052631578948\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "\n",
    "SVM = GridSearchCV(SVC(), param_grid=param_grid ,cv=5, scoring='accuracy',n_jobs=-1)\n",
    "SVM.fit(x_train, y_train)\n",
    "\n",
    "print(SVM.best_params_)\n",
    "print(SVM.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb89f73b",
   "metadata": {},
   "source": [
    "###  Testing The Best Model\n",
    "after trying different models we have come to a conclusion that our random forest is the best model. therefor we use it to test our model below. to do that we predict using x test and then check the accuracy and confusion matrix\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6c69a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RF.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e9c7fd",
   "metadata": {},
   "source": [
    "### Classification Report\n",
    "the table below gives us the report where it shows that the accuracy is 88. and we can improve it using different \n",
    "methods for example collecting more data. feature engineering and etc. in term of precision the model is doing well specially in normal and depression. as we can see below bipolar type-1 is 80 which means the model is correct 80 percent of the time at identifying the bipolar type-1 or 80% percent of hte instances that were predicted as bipolar type-1 were actually true. recall measures our model which in this case it says that the model correctly identify the 80 percent of the positive instances out of all positive instances. f1 score is the mean of pre an recall also support is number of accurencies.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6b8c90e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "Bipolar Type-1       0.80      0.80      0.80         5\n",
      "Bipolar Type-2       0.88      0.88      0.88         8\n",
      "    Depression       1.00      0.50      0.67         2\n",
      "        Normal       0.90      1.00      0.95         9\n",
      "\n",
      "      accuracy                           0.88        24\n",
      "     macro avg       0.89      0.79      0.82        24\n",
      "  weighted avg       0.88      0.88      0.87        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6324f09",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "confusion below here represents true positive,true negative, false positive and false negative. it divides them into 4 classes. first calss which starts with 4 indicates that 4 instances were calsfied as class 1, 1 misclasified as calss 2 and zero zero for class 3 and 4. class 2 which starts with 7 indicates that 7 instances were classified correctly as class 2 and zero zero for class 3 and 4.and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "495dab5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 1, 0, 0],\n",
       "       [1, 7, 0, 0],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 0, 0, 9]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d025a980",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "we are using the dataset mentioned above to predict mental disorder. our target expert diagnose and other columns\n",
    "are our features. we use features to predict our target. since we are using labeld data therefor its supervised \n",
    "learning. we are using classifcation algorithms because our target is categorical and the problem is a classification problem. we use three most common algorithms such logistic regression,, random forest and support vector machine. then we choose the one with the highest accuracy and test our model on it. then we print the confusion matrix and classification report to know more about our pypline's prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
